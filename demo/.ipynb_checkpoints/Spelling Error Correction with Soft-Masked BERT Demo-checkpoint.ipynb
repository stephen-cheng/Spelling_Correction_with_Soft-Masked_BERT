{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/2.2.2/libexec/bin/python3.8\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "from transformers import BertConfig,BertModel, BertTokenizer\n",
    "from transformers.modeling_bert import BertEmbeddings, BertEncoder,BertPooler,BertPreTrainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Proposed in the Paper of ACL 2020: Spelling Error Correction with Soft-Masked BERT(2020_ACL)'''\n",
    "\n",
    "class Soft_Masked_BERT(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        # self.config contains all parameters of Correction_Network Bert network.\n",
    "        self.config = config\n",
    "        \n",
    "        '''1) build layers of Detection_Network'''\n",
    "        self.enc_bi_gru = torch.nn.GRU(input_size=768, hidden_size=256, dropout=0.2, bidirectional=True)\n",
    "        self.detection_network_dense_out = torch.nn.Linear(512, 2)\n",
    "        self.soft_masking_coef_mapping = torch.nn.Linear(512, 1)\n",
    "        \n",
    "        '''2) build 3 layers of Correction_Network in BertModel'''\n",
    "        # embedding layer\n",
    "        self.embeddings = BertEmbeddings(config)\n",
    "        # 12-layer multi-head self attention\n",
    "        self.encoder = BertEncoder(config)\n",
    "        # pooling-layer BertPooler\n",
    "        self.pooler = BertPooler(config)\n",
    "        self.init_weights()\n",
    "        \n",
    "        self.mask_embeddings = self.embeddings.word_embeddings.weight[103]  # 此时,mask_embedding张量的形状为(768,)\n",
    "        \n",
    "        self.soft_masked_bert_dense_out = torch.nn.Linear(self.config.hidden_size, self.embeddings.word_embeddings.weight.shape[0])\n",
    "        \n",
    "        \n",
    "    def get_input_embeddings(self):\n",
    "        return self.embeddings.word_embeddings\n",
    "\n",
    "    def set_input_embeddings(self, value):\n",
    "        self.embeddings.word_embeddings = value\n",
    "\n",
    "    def _prune_heads(self, heads_to_prune):\n",
    "        \"\"\" Prunes heads of the model.\n",
    "            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n",
    "            See base class PreTrainedModel\n",
    "        \"\"\"\n",
    "        for layer, heads in heads_to_prune.items():\n",
    "            self.encoder.layer[layer].attention.prune_heads(heads)\n",
    "             \n",
    "            \n",
    "    '''build Detection_Network'''\n",
    "    def Detection_Network(self, input_embeddings: torch.Tensor, attention_mask: torch.Tensor):\n",
    "        # input_embeddings:(seq_len, batch_size, embed_size)->(seq_len, batch_size, 768)\n",
    "        # attention_mask:(batch_size, seq_len)\n",
    "        # input embedding: every sentence's character's word embedding+position embedding+segment embeddings\n",
    "        h_0 = torch.zeros(2, input_embeddings.shape[1], 256)\n",
    "        bi_gru_final_hidden_layer = self.enc_bi_gru(input_embeddings, h_0)[0]\n",
    "        bi_gru_final_hidden_layer = bi_gru_final_hidden_layer.permute(1,0,2)\n",
    "        \n",
    "        # (batch_size, seq_len, 2)\n",
    "        detection_network_output = self.detection_network_dense_out(bi_gru_final_hidden_layer) \n",
    "        # (batch_size, seq_len, 1)\n",
    "        soft_masking_coefs = torch.nn.functional.sigmoid(self.soft_masking_coef_mapping(bi_gru_final_hidden_layer) ) \n",
    "        # (batch_size, seq_len,1)\n",
    "        attention_mask = attention_mask.unsqueeze(dim=2)\n",
    "        \n",
    "    \n",
    "        attention_mask = (attention_mask != 0) \n",
    "        soft_masking_coefs[~attention_mask] = 0\n",
    "        \n",
    "        return detection_network_output, soft_masking_coefs\n",
    "    \n",
    "    \n",
    "    '''build Soft Masking Connection'''\n",
    "    def Soft_Masking_Connection(self,input_embeddings: torch.Tensor,\n",
    "               mask_embeddings: torch.Tensor,\n",
    "               soft_masking_coefs: torch.Tensor):\n",
    "        \n",
    "        soft_masked_embeddings = soft_masking_coefs * mask_embeddings + (1 - soft_masking_coefs) * input_embeddings\n",
    "        \n",
    "        return soft_masked_embeddings\n",
    "        \n",
    "        \n",
    "    \n",
    "    '''forward'''\n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, position_ids=None,\n",
    "                head_mask=None, inputs_embeds=None, encoder_hidden_states=None, encoder_attention_mask=None,\n",
    "                output_attentions=None,):\n",
    "        \n",
    "        input_ids = input_ids.long()\n",
    "        attention_mask = attention_mask.long()\n",
    "        token_type_ids = token_type_ids.long()\n",
    "        position_ids = position_ids.long()\n",
    "        \n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        \n",
    "        if input_ids is not None and inputs_embeds is not None:\n",
    "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
    "        elif input_ids is not None:\n",
    "            input_shape = input_ids.size()\n",
    "        elif inputs_embeds is not None:\n",
    "            input_shape = inputs_embeds.size()[:-1]\n",
    "        else:\n",
    "            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
    "\n",
    "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
    "\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones(input_shape, device=device)\n",
    "        if token_type_ids is None:\n",
    "            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
    "\n",
    "        # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n",
    "        # ourselves in which case we just need to make it broadcastable to all heads.\n",
    "        extended_attention_mask: torch.Tensor = self.get_extended_attention_mask(attention_mask, input_shape, device)\n",
    "\n",
    "        # If a 2D or 3D attention mask is provided for the cross-attention\n",
    "        # we need to make broadcastabe to [batch_size, num_heads, seq_length, seq_length]\n",
    "        if self.config.is_decoder and encoder_hidden_states is not None:\n",
    "            encoder_batch_size, encoder_sequence_length, _ = encoder_hidden_states.size()\n",
    "            encoder_hidden_shape = (encoder_batch_size, encoder_sequence_length)\n",
    "            if encoder_attention_mask is None:\n",
    "                encoder_attention_mask = torch.ones(encoder_hidden_shape, device=device)\n",
    "            encoder_extended_attention_mask = self.invert_attention_mask(encoder_attention_mask)\n",
    "        else:\n",
    "            encoder_extended_attention_mask = None\n",
    "\n",
    "        # Prepare head mask if needed\n",
    "        # 1.0 in head_mask indicate we keep the head\n",
    "        # attention_probs has shape bsz x n_heads x N x N\n",
    "        # input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\n",
    "        # and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\n",
    "        head_mask = self.get_head_mask(head_mask, self.config.num_hidden_layers)\n",
    "    \n",
    "        input_embeddings = self.embeddings(input_ids=input_ids, position_ids=position_ids, token_type_ids=token_type_ids, inputs_embeds=inputs_embeds)\n",
    "        # (seq_len, batch_size, embed_size)->(seq_len, batch_size, 768).\n",
    "        input_embeddings = input_embeddings.permute(1,0,2)\n",
    "        \n",
    "        detection_network_output, soft_masking_coefs = self.Detection_Network(input_embeddings=input_embeddings, attention_mask=attention_mask)\n",
    "        \n",
    "        input_embeddings = input_embeddings.permute(1,0,2)\n",
    "        \n",
    "        self.mask_embeddings = self.mask_embeddings.unsqueeze(0).unsqueeze(0).repeat(1,input_embeddings.shape[1],1).repeat(input_embeddings.shape[0],1,1)\n",
    "        soft_masked_embeddings = self.Soft_Masking_Connection(input_embeddings=input_embeddings, mask_embeddings=self.mask_embeddings,\n",
    "                                                             soft_masking_coefs=soft_masking_coefs)\n",
    "        \n",
    "        encoder_outputs = self.encoder(soft_masked_embeddings, \n",
    "                                       attention_mask=extended_attention_mask, \n",
    "                                       head_mask=head_mask, \n",
    "                                       encoder_hidden_states=encoder_hidden_states, \n",
    "                                       encoder_attention_mask=encoder_extended_attention_mask,)\n",
    "        sequence_output = encoder_outputs[0]\n",
    "        pooled_output = self.pooler(sequence_output)\n",
    "        \n",
    "        # add hidden_states and attentions if they are here\n",
    "        outputs = (sequence_output, pooled_output,) + encoder_outputs[1:]\n",
    "        \n",
    "        bert_output_final_hidden_layer = outputs[0]\n",
    "        residual_connection_outputs = bert_output_final_hidden_layer + input_embeddings\n",
    "        final_outputs = self.soft_masked_bert_dense_out(residual_connection_outputs)        \n",
    "        \n",
    "        return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n",
      "Some weights of Soft_Masked_BERT were not initialized from the model checkpoint at ./bert_chinese_model/pytorch_model.bin and are newly initialized: ['enc_bi_gru.weight_ih_l0', 'enc_bi_gru.weight_hh_l0', 'enc_bi_gru.bias_ih_l0', 'enc_bi_gru.bias_hh_l0', 'enc_bi_gru.weight_ih_l0_reverse', 'enc_bi_gru.weight_hh_l0_reverse', 'enc_bi_gru.bias_ih_l0_reverse', 'enc_bi_gru.bias_hh_l0_reverse', 'detection_network_dense_out.weight', 'detection_network_dense_out.bias', 'soft_masking_coef_mapping.weight', 'soft_masking_coef_mapping.bias', 'soft_masked_bert_dense_out.weight', 'soft_masked_bert_dense_out.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 21128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9036,  0.2973, -0.3927,  ..., -0.0348,  0.7091, -0.8938],\n",
       "         [ 0.2234, -0.5968, -0.2733,  ..., -0.9220,  0.5116, -0.6441],\n",
       "         [ 0.8974, -0.2807,  0.1874,  ..., -0.1327,  0.5778, -1.0925],\n",
       "         [ 2.0729, -1.0279, -0.9150,  ..., -1.0137,  0.4178,  0.4004],\n",
       "         [ 1.4600, -0.5652,  0.6940,  ...,  0.5275,  0.7452, -0.6747],\n",
       "         [ 0.7080, -0.9226, -0.4265,  ...,  0.8992, -0.6006,  0.1721]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "config = BertConfig.from_pretrained(\"./bert_chinese_model/bert_config.json\")\n",
    "tokenizer = BertTokenizer.from_pretrained('./bert_chinese_model/vocab.txt')\n",
    "soft_masked_bert = Soft_Masked_BERT.from_pretrained(\"./bert_chinese_model/pytorch_model.bin\", config=config)\n",
    "\n",
    "text = '上海的填空美'\n",
    "token = tokenizer.tokenize(text)\n",
    "ids = tokenizer.convert_tokens_to_ids(token)\n",
    "input_ids = torch.Tensor([ids]).long()\n",
    "# input_ids = torch.Tensor([[101,768,867,117,102,0]]).long()\n",
    "attention_mask = torch.Tensor([[1,1,1,1,1,0]]).long()\n",
    "token_type_ids = torch.Tensor([[0,0,0,0,0,0]]).long()\n",
    "position_ids = torch.Tensor([[0,1,2,3,4,5]]).long()\n",
    "\n",
    "output = soft_masked_bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, position_ids=position_ids)\n",
    "print(output.shape)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11286)\n",
      "tensor(1228)\n",
      "tensor(8451)\n",
      "tensor(20571)\n",
      "tensor(14735)\n",
      "tensor(9943)\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "for i in output[0]:\n",
    "    ids = torch.argmax(i)\n",
    "    print(ids)\n",
    "    tokens = tokenizer.convert_ids_to_tokens([ids])\n",
    "    string = tokenizer.convert_tokens_to_string(tokens)\n",
    "    words.append(string)\n",
    "text = \"\".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'##more労love##頁##嘿##hy'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
